{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Collecting Produce Images\n",
    "- Collect 300 images of different vegetables [google-images-download](https://pypi.org/project/google-images-download/#usage-using-command-line-interface)\n",
    "- Afterwards, inspect each image and remove non-relevant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to automate image collection and renaming of figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download images\n",
    "def downloadVeg(list_veg, n_img=300):\n",
    "    '''Function to download images from google\n",
    "    Input:\n",
    "        list_veg - list of veggies, e.g., ['tomato','carrot']\n",
    "        n_img    - the number of images to collect\n",
    "    '''\n",
    "    for each in list_veg:\n",
    "        arguments = {\"keywords\":each,\n",
    "                 \"limit\":n_img,\n",
    "                 \"print_urls\":False,\n",
    "                \"chromedriver\":'/Users/jhonsen/Downloads/chromedriver'}   #creating list of arguments\n",
    "        response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "        paths = response.download(arguments)   #passing the arguments to the function\n",
    "\n",
    "# Python3 code to rename multiple files in a directory or folder   \n",
    "def rename(directory, prefix): \n",
    "    ''' Function renames files within a directory\n",
    "    Input:\n",
    "        directory - in string\n",
    "        prefix    - in string, the prefix of filenames\n",
    "    '''\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory): \n",
    "        dst = prefix + str(i) + \".jpg\"\n",
    "        src = directory + filename \n",
    "        dst = directory + dst  \n",
    "        # rename() function will \n",
    "        # rename all the files \n",
    "        os.rename(src, dst) \n",
    "        i += 1\n",
    "        \n",
    "def renamePhotos(list_veg):\n",
    "    ''' function to rename the photos inside folder\n",
    "    '''\n",
    "    for each in list_veg:\n",
    "        rename(f'../data/images/raw/{each}/', each)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the types of images to collect. Some will be used to train the model.\n",
    "vegetables = ['tomato','bell pepper','asparagus', 'broccoli','spinach',\n",
    "              'eggplant','zucchini','scallion','celery',\n",
    "              'cauliflower','spinach','bok choy vegetable','kale',\n",
    "              'brussels sprouts vegetable','cabbage','bean sprouts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START Collecting Images! \n",
    "\n",
    "# >>>>>>> This function will take a while to complete<<<<<\n",
    "# >>>> It also outputs a huge number of text output <<<<<<\n",
    "\n",
    "downloadVeg(vegetables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename photos so the filenames are labeled in numerical order \n",
    "\n",
    "renamePhotos(vegetables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After inspecting & removing non-relevant files in `/data/images/raw/` directory, split them into train & test groups,\n",
    "- Place those images in `/data/veggies/train` and `/data/veggies/test` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe collection via webscraping Epicurious\n",
    "To collect recipes and images of the recipes, I utilized others' webscrapers:\n",
    "1. Go to terminal and **clone** this [recipe-box](https://github.com/jhonsen/recipe-box) repo, which has a few commits ahead of its upstream ([Ryan's recipe-box](https://github.com/rtlee9/recipe-box)) to account for epicurious page-changes and to collect nutritional facts during scraping.  In particular, I made a few changes to the following python scripts:\n",
    "        - get_pictures.py => updated image url\n",
    "        - get_recipes.py  => added a few lines to scrape nutritional facts\n",
    "2. Inside `./src/`-folder of recipe-box repo, clone this [recipe-scraper](https://github.com/rtlee9/recipe-scraper), which is where the scraper script imported from\n",
    "3. Run scraper from top directory, e.g., `$ python src/get_recipes.py --epi --multi --sleep 2` (see doc for args details)\n",
    "4. Briefly inspect the output file in `./data/`-folder. My output is called **recipes_raw_epi.json**, which is a json file that will be parsed in [Step2_Cleaning.ipynb](./Step2_Cleaning.ipynb). Since this file exceeds the limit allowed by Github size (>100MB+), it's not included in this repo. \n",
    "5. Move the **recipes_raw_epi.json** file to the [data](../data) folder of this repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
